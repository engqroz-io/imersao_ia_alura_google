# -*- coding: utf-8 -*-
"""busca_docs_using_embenddings_and_gemini_api.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T2FNXahxudg9Dvr6-XpyLVBTxGt63EF_
"""

!pip install -q -U google-generativeai #instala a biblioteca do google para utilização da API Key / Gemini

import numpy as np
import pandas as pd
import google.generativeai as genai

GOOGLE_API_KEY="AIzaSyDTpww1R3TBjPGJWU1lGoyGqaZ7fqyBrtY"
genai.configure(api_key=GOOGLE_API_KEY)

for m in genai.list_models():
  # print(m.supported_generation_methods)
  if 'embedContent' in m.supported_generation_methods:
    print(m.name)

text = "Vingadores"
result = genai.embed_content(model="models/embedding-001", content=text)
print(result['embedding'])

print(len(result['embedding']))

title = "A próxima geração de IA para desenvolvedores e Google Workspace"
sample_text = ("Título: A próxima geração de IA para desenvolvedores e Gogole Workspace"
  "/n"
  "Artigo completo:/n"
  "/n"
  "Gemini API & Google AI Studio: Uma maneira de explorar e crar protótipos com aplicações de IA generativa")

embeddings = genai.embed_content(model="models/embedding-001",
                                 content=sample_text,
                                 title=title,
                                 task_type="RETRIEVAL_DOCUMENT")

print(embeddings)

DOCUMENT1 = {
    "Título":"Operação do sistema de controle climático",
    "Conteúdo":"O Googlecar tem um sistema de controle climático que permite ajustar a temperatura e o fluxo de ar no carro." }

DOCUMENT2 = {
    "Título":"TouchScreen",
    "Conteúdo":"O Googlecar tem uma grande tela sensível ao toque que fornece acesso a uma variedade de recursos, incluindo navegação." }

DOCUMENT3 = {
    "Título":"Mudança de marchas",
    "Conteúdo":"Seu Googlecar tem transmissão automática." }

documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]

df = pd.DataFrame(documents)
df.columns = ["Titulo", "Conteudo"]
df

def embedding_fn(title, text, model):
  return genai.embed_content(model=model,
                             content=text,
                             title=title,
                             task_type="RETRIEVAL_DOCUMENT")["embedding"]

model = "models/embedding-001"
df["Embeddings"] = df.apply(lambda row: embedding_fn(title=row["Titulo"], text=row["Conteudo"], model=model), axis=1)
df

def gerar_e_buscar_consulta(consulta, document, model):
  embedding_de_consulta = genai.embed_content(model=model,
                                              content=consulta,
                                              task_type="RETRIEVAL_QUERY")["embedding"]

  produtos_escalares = np.dot(np.stack(df["Embeddings"]), embedding_de_consulta)

  indice = np.argmax(produtos_escalares)
  return df.iloc[indice]["Conteudo"]

consulta = "Como faço para trocar de marcha no carro do Google?"

trecho = gerar_e_buscar_consulta(consulta, df, model)
print(trecho)

generation_config = {
    "temperature": 0.5,
    "candidate_count": 1
}

prompt = f"Reescreva esse texto de uma forma mais desconstrída, sem adicionar informações que não façam parte do texto: {trecho}"

model_2 = genai.GenerativeModel("gemini-1.0-pro", generation_config=generation_config)
response = model_2.generate_content(prompt)
print(response.text)

